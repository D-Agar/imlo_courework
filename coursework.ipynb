{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Intelligent Systems - Individual Project Assessment\n",
    "I aim to split the code into 3 sections:\n",
    "1. Generating and analysing the datset\n",
    "2. Developing my classification model\n",
    "3. Training my model"
   ],
   "id": "3c02b4c20834a4a8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.529640Z",
     "start_time": "2024-04-30T14:13:47.525764Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import scipy.io as sio\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 275
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.556275Z",
     "start_time": "2024-04-30T14:13:47.551786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set the selected device for the tensors\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(torch.cuda.get_device_name(device))\n",
    "torch.set_default_device(device)"
   ],
   "id": "848484533890309c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 276
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "f7e918a0a496f59f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Augmentation\n",
    "After inspection of the dataset, we have PIL images. Therefore, we will convert these to Tensors.\n",
    "\n",
    "The values used for the normalisation of data were calculated from the ImageNet training datase"
   ],
   "id": "47ed70104b71258f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.564675Z",
     "start_time": "2024-04-30T14:13:47.557393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We perform random transformations to better generalise the training dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "c48f59331aa7647",
   "outputs": [],
   "execution_count": 277
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Downloading and splitting the dataset",
   "id": "610a373e39b3741d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.602878Z",
     "start_time": "2024-04-30T14:13:47.565702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I will download the data from PyTorch's website and use the appropriate data loader\n",
    "train_dataset = datasets.Flowers102(\n",
    "    root='flowers102',\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "valid_dataset = datasets.Flowers102(\n",
    "    root='flowers102',\n",
    "    split=\"val\",\n",
    "    download=True,\n",
    "    transform=valid_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.Flowers102(\n",
    "    root='flowers102',\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Get the targets and ids\n",
    "image_labels = sio.loadmat(\"flowers102/flowers-102/imagelabels\")\n",
    "setids = sio.loadmat(\"flowers102/flowers-102/setid\")"
   ],
   "id": "bd6d67145590aa00",
   "outputs": [],
   "execution_count": 278
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.616143Z",
     "start_time": "2024-04-30T14:13:47.604884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# look at the first training sample\n",
    "image, label = train_dataset[0]\n",
    "print(f\"Image shape: {image.shape} -> [batch, height, width]\")\n",
    "print(f\"Datatype: {image.type}\")\n",
    "print(f\"Label: {image_labels['labels'][label]}\")\n",
    "print(f\"Device tensor is stored on: {image.device}\")"
   ],
   "id": "abb62d68edf8bc2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 224, 224]) -> [batch, height, width]\n",
      "Datatype: <built-in method type of Tensor object at 0x000001BD04806670>\n",
      "Label: [77 77 77 ... 62 62 62]\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "execution_count": 279
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "#### Hyperparameters"
   ],
   "id": "eed9848820c891b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Residual Block\n",
    "As I wish to implement a model based upon a Residual Network, I must first build a *Residual Block*. A basic block consists of two sequential 3x3 convolutional layers and a residual connection, where the input and output dimensions of the layers are the same."
   ],
   "id": "d9850b5b75599616"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.623241Z",
     "start_time": "2024-04-30T14:13:47.617148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Create the skip connection len(in_channels) != len(out_channels) or stride != 1\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x.clone()\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # Skip connection\n",
    "        residual = self.shortcut(residual)\n",
    "        x += residual\n",
    "        x = self.relu(x)\n",
    "        return x"
   ],
   "id": "836368053b1a6419",
   "outputs": [],
   "execution_count": 280
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ResNet Architecture",
   "id": "c2f17a725ce990a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.633808Z",
     "start_time": "2024-04-30T14:13:47.624244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, ResidualBlock, layers, image_channels, num_classes):\n",
    "        \"\"\"\n",
    "        My Neural Network architecture implemented in PyTorch.\n",
    "        :param ResidualBlock: A residual block class\n",
    "        :param layers: A list stating how many times we wish to use the residual block for each layer\n",
    "        :param image_channels: the number of channels of the input image\n",
    "        :param num_classes: the number of classes\n",
    "        \"\"\"\n",
    "        super(MyNN, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        # Based upon a residual network, the first layer is a convolutional layer producing 64 channels\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Architecture's layers\n",
    "        self.layer1 = self.make_layer(ResidualBlock, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, layers[2], out_channels=128, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, layers[3], out_channels=512, stride=2)\n",
    "        \n",
    "        # Get a single value at the end (scalar)\n",
    "        self.avgPool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # initial layer setup for the network\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # The architecture's layers\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Make it the correct dimension\n",
    "        x = self.avgPool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "            \n",
    "    def make_layer(self, ResidualBlock, n_res_blocks, out_channels, stride):\n",
    "        layers = []\n",
    "        \n",
    "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels     # no expansion as input channels must equal output channels\n",
    "        \n",
    "        for i in range(1, n_res_blocks):\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels))\n",
    "        \n",
    "        # Return a sequence of modules that is the same as the layers list (including order)  \n",
    "        return nn.Sequential(*layers)"
   ],
   "id": "d48ad17670c76f80",
   "outputs": [],
   "execution_count": 281
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.668231Z",
     "start_time": "2024-04-30T14:13:47.634814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = MyNN(ResidualBlock, [2, 2, 2, 2], 3, 1)\n",
    "net.to(device)\n",
    "print(net)"
   ],
   "id": "9858f155b380e71b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNN(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgPool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 282
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.673219Z",
     "start_time": "2024-04-30T14:13:47.669235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the learnable parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ],
   "id": "22bb995aaf2b22f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "torch.Size([64, 3, 7, 7])\n"
     ]
    }
   ],
   "execution_count": 283
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Network",
   "id": "6f3b52e957e6c22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.684805Z",
     "start_time": "2024-04-30T14:13:47.675224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(30)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "a6f5c1a8ae9dfe12",
   "outputs": [],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.707595Z",
     "start_time": "2024-04-30T14:13:47.685809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# optimiser = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# try to predict the first training sample\n",
    "image, label = train_dataset[0]\n",
    "image = image.to(device)\n",
    "image"
   ],
   "id": "f845be5bbb8771be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6563,  0.5193,  0.6392,  ..., -1.8097, -1.0733, -0.6452],\n",
       "         [ 0.6734,  0.5707,  0.7077,  ..., -1.8268, -1.0733, -0.6794],\n",
       "         [ 0.7419,  0.6734,  0.7591,  ..., -1.7925, -1.0390, -0.7308],\n",
       "         ...,\n",
       "         [ 0.5022,  0.5193,  0.4508,  ..., -0.0972,  0.5536,  0.8276],\n",
       "         [ 0.5193,  0.5364,  0.4166,  ..., -0.1486,  0.5707,  0.8276],\n",
       "         [ 0.5193,  0.4851,  0.4166,  ..., -0.1143,  0.5878,  0.8961]],\n",
       "\n",
       "        [[ 0.3803,  0.2402,  0.3627,  ..., -1.5980, -0.7577, -0.2850],\n",
       "         [ 0.3978,  0.2752,  0.3978,  ..., -1.5805, -0.7402, -0.3200],\n",
       "         [ 0.4503,  0.3627,  0.4503,  ..., -1.5105, -0.7052, -0.3375],\n",
       "         ...,\n",
       "         [ 0.0126,  0.0301, -0.0224,  ..., -0.0049,  0.6078,  0.9755],\n",
       "         [ 0.0301,  0.0476, -0.0224,  ..., -0.0049,  0.6779,  0.9230],\n",
       "         [ 0.0651,  0.0476, -0.0049,  ...,  0.0476,  0.7304,  0.9580]],\n",
       "\n",
       "        [[ 1.2108,  1.0539,  1.1759,  ..., -1.5953, -0.9504, -0.6193],\n",
       "         [ 1.2282,  1.0888,  1.2282,  ..., -1.6127, -0.9678, -0.6715],\n",
       "         [ 1.2980,  1.1934,  1.2805,  ..., -1.5779, -0.9678, -0.7238],\n",
       "         ...,\n",
       "         [ 1.0017,  1.0191,  0.9842,  ..., -1.1944, -0.3055,  0.1302],\n",
       "         [ 1.0191,  1.0365,  0.9668,  ..., -1.3164, -0.4101,  0.1825],\n",
       "         [ 1.0539,  1.0191,  0.9842,  ..., -1.4036, -0.5147,  0.1476]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 285
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.712973Z",
     "start_time": "2024-04-30T14:13:47.708599Z"
    }
   },
   "cell_type": "code",
   "source": "print(image.unsqueeze(0).shape)",
   "id": "bc57d85ea44f8163",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 286
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.728246Z",
     "start_time": "2024-04-30T14:13:47.713976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = net(image.unsqueeze(0))\n",
    "prediction.shape"
   ],
   "id": "1ece79d856cdf81b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:13:47.751056Z",
     "start_time": "2024-04-30T14:13:47.729250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compare to label\n",
    "print(f\"Target label: {label}\")\n",
    "print(f\"Prediction: {prediction}\")"
   ],
   "id": "f3a01c5ff867834c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label: 0\n",
      "Prediction: tensor([[1.6499]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 288
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
